1. Introduction


Employee information by employeeId. 
Operations to be performed: insert, search, delete


Different ways we can implement?
Arrays and Linked Lists:-  search O(n), if sorting then insertion and deletion costly
Balanced BST:- All operations O(logn)
Direct Access Table:- Definitely O(1) all operations, but limitations with key size

Hashing
Hashing is an improvement over Direct Access Table. The idea is to use hash function that converts a given key to a smaller number and uses the small number as index in a table called hash table.

Hash Function: A function that converts a given big key/string to a small practical integer value. The mapped integer value is used as an index in hash table. 
A good hash function should have following properties
   1) Efficiently computable.
   2) Should uniformly distribute the keys (Each table position equally likely for each key)
   Ex: few digits of big number or its combination

Hash Table: An array that stores pointers to records corresponding to a given key. An entry in hash table is NIL if no existing key has hash function value equal to the index for the entry.

Collision Handling: Since a hash function gets us a small number for a big key, there is possibility that two keys result in same value. The situation where a newly inserted key maps to an already occupied slot in hash table is called collision and must be handled using some collision handling technique. 



2. Separate Chaining for Collision Handling


The idea is to make each cell of hash table point to a linked list of records that have same hash function value. Chaining is simple, but requires additional memory outside the table.

Let us consider a simple hash function as “key mod 7” and sequence of keys as 50, 700, 76, 85, 92, 73, 101.


Advantages:
1) Simple to implement.
2) Hash table never fills up, we can always add more elements to chain.
3) Less sensitive to the hash function or load factors.
4) It is mostly used when it is unknown how many and how frequently keys may be inserted or deleted.

Disadvantages:
1) Cache performance of chaining is not good as keys are stored using linked list [locality of reference]. Open addressing provides better cache performance as everything is stored in same table.
2) Wastage of Space (Some Parts of hash table are never used)
3) If the chain becomes long, then search time can become O(n) in worst case.
4) Uses extra space for links.


Performance of Chaining:
Performance of hashing can be evaluated under the assumption that each key is equally likely to be hashed to any slot of table (simple uniform hashing).
m = Number of slots in hash table 
n = Number of keys to be inserted in hash table 
Load factor α = n/m 
Expected time to search = O(1 + α)
Expected time to insert/delete = O(1 + α)
Time complexity of search insert and delete is O(1) if  α is O(1)



3. Open addressing for Collision Handling


In open addressing, all elements are stored in the hash table itself.  So at any point, size of table must be greater than or equal to total number of keys.


Insert(k): Keep probing until an empty slot is found. Once an empty slot is found, insert k.
Search(k): Keep probing until slot’s key doesn’t become equal to k or an empty slot is reached.
Delete(k): Delete operation is interesting. If we simply delete a key, then search may fail. So slots of deleted keys are marked specially as “deleted”.
Insert can insert an item in a deleted slot, but search doesn’t stop at a deleted slot.


Open Addressing is done following ways:
	a) Linear Probing: In linear probing, we linearly probe for next slot. For example, typical gap between two probes is 1. Let hash(x) be the slot index computed using hash function and S be the table size, thus if hash(x) is full, we check hash(x)+1, and so on….
Let us consider a simple hash function as “key mod 7” and sequence of keys as 50, 700, 76, 85, 92, 73, 101.


	Clustering: The main problem with linear probing is clustering, many consecutive elements form groups and it starts taking time to find a free slot or to search an element.


	b) Quadratic Probing We look for i2‘th slot in i’th iteration. Let hash(x) be the slot index computed using hash function.  
If slot hash(x) % S is full, then we try (hash(x) + 1*1) % S
If (hash(x) + 1*1) % S is also full, then we try (hash(x) + 2*2) % S
	
	
	c) Double Hashing We use another hash function hash2(x) and look for i*hash2(x) slot in i’th rotation. Let hash(x) be the slot index computed using hash function.  
If slot hash(x) % S is full, then we try (hash(x) + 1*hash2(x)) % S
If (hash(x) + 1*hash2(x)) % S is also full, then we try (hash(x) + 2*hash2(x)) % S


Comparison of above three:

Linear probing has the best cache performance, but suffers from clustering. One more advantage of Linear probing is easy to compute.
Quadratic probing lies between the two in terms of cache performance and clustering.
Double hashing has poor cache performance but no clustering. Double hashing requires more computation time as two hash functions need to be computed.



